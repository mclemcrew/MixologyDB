Speaker SPEAKER_00: 3640.5s - 3645.7s
Cool. All right. I'm going to read off some questions just to make sure I'm not
 missing absolutely everything.

Speaker SPEAKER_00: 3646.3s - 3683.8s
Um, but the first question I have is how would you describe the ideal workflow
 when using a co-creative music mixing agent?
 So would you like it to be more of a teacher or like a creative partner and
 kind of like how you experienced here, or would you like it to learn industry
 standard techniques necessarily and say, you know, Uh, one of your suggestions
 was like, okay, well, I don't always mix for rock.
 So what do people normally commonly do?
 Or would you like it to mainly provide suggestions and recommendations
 based on your own musical tastes?
 So what you normally do, um, and either of you can answer, um, if you
 have like strong feelings, go for it.

Speaker SPEAKER_00: 3685.6s - 3687.4s
Otherwise I'll ask Jackie first.

Speaker SPEAKER_06: 3687.8s - 3710.5s
Well, I would like it to be yes, sort of more alerting industry
 standards and then give you suggestions based on that like
 what you asked sort of like a tutorial like if I Google how to
 mix like garage house music, I want kind of like the standards
 for that or maybe it would even give me like a template or a
 preset mix to start with that I can sort of mess with and play

Speaker SPEAKER_00: 3711.5s - 3721.6s
Should it get the intentionality behind that?
 That was one thing that was discussed in terms of like reasons behind why an EQ
 is a certain way or a reverb or just blanket, here you go.

Speaker SPEAKER_06: 3721.7s - 3730.8s
I think it should, but only as a read more.
 Because not everyone's going to need or want it all the time,
 but there will be people who ask.

Speaker SPEAKER_03: 3726.7s - 3727.0s


Speaker SPEAKER_02: 3731.5s - 3731.7s


Speaker SPEAKER_00: 3731.7s - 3731.8s


Speaker SPEAKER_00: 3732.9s - 3734.3s
And then TJ, do you have any questions?

Speaker SPEAKER_01: 3732.9s - 3733.7s


Speaker SPEAKER_01: 3734.9s - 3783.6s
I would totally agree with a lot of that.
 I think I want, I do want industry standard
 'cause like I listen almost exclusively
 to pop and alternative pop.
 So like I know sort of the rock sound
 but it was really helpful for you to like sort of confirm
 or affirm some of the decisions I made.
 Like, yes, the drums should be prominent.
 Yes, the guitar should be like,
 it was nice to hear you say
 like you were also thinking distortion.
 Those are things that I would definitely dial way back
 in a pop mix.
 But so I think you provided some industry standard stuff
 that was helpful.
 But I think what was even more helpful
 was that I did still have a vision
 for like things that I wanted to do with it.
 And two things that I would want
 like a co-creative AI mixing partner to do
 would be to like,

Speaker SPEAKER_01: 3784.7s - 3796.5s
have me be able to try to voice my creative ideas to it, and
 maybe have it give me a couple ways of achieving that.
 [BLANK_AUDIO]

Speaker SPEAKER_01: 3797.7s - 3798.9s
So not even different.

Speaker SPEAKER_00: 3798.1s - 3804.2s
Do you mean different ways in terms of like different audio effects that could be applied to achieve a similar sound or?

Speaker SPEAKER_01: 3803.5s - 3842.3s
- Yeah, so there's an industry standard way of doing it,
 but if it could also say like you could, you could achieve,
 you could potentially achieve that effect by doing this,
 this and this could also be helpful.
 So something that can give industry standard,
 but also when you get more into the nitty gritty
 of mixing stuff, like you and I were making small,
 small tweaks together that probably deviate
 from industry standard, but having someone who can be like,
 yes or no or less or more.
 I think that's something that kind of helps
 with fine tuning maybe.

Speaker SPEAKER_06: 3841.9s - 3861.5s
Yeah, it would be kind of hard. I don't know how easy it would be to program an AI to do this, but it just seems like different parts of the song also need different things and it would it would be able to tell that ideally, like, Oh, this is the big guitar solo, or Oh, this tracks like an accent guitar track. So it should have this effect on it, which is hard to do. But

Speaker SPEAKER_00: 3863.3s - 3915.6s
- No, that, yeah, I can tell you from the inside
 it is very difficult to do, but yeah, that makes sense.
 In terms of giving the feedback,
 you're both speaking almost like it's textual
 as like maybe a chat bot,
 but is there another form you could think of?
 Like, is it, should it be personified in a voice?
 Does that help?
 Or is it always text?
 Or is there another way, like even, you know,
 if I was giving an explanation in an EQ,
 what if I highlighted portions of the wave?
 So in terms of like, oh, you should cut the low end
 and then, you know, highlight the low end
 for people who aren't necessarily sure where exactly.
 So like, oh, you could,
 like you were trying to find the transient on that base.
 Would it be helpful to necessarily like highlight those
 things in terms of an explanation like that visually,
 as well as textual or just textual or another way?

Speaker SPEAKER_00: 3917.4s - 3923.0s
And either of you can totally go if you have any strong feelings because most of the AI right now is just text

Speaker SPEAKER_06: 3923.3s - 3935.9s
I would love it to be like a personified like voice, especially if you're like, I can't
 find the low end.
 And Tom is like, it's right here and it highlights that would be like ideal, but maybe that's
 too much for some people.

Speaker SPEAKER_01: 3937.5s - 4001.6s
I was gonna say the same thing.
 I think a lot of people might prefer just the text,
 but I love people and love like talking
 and hearing someone talk,
 which I also get with music that could be a little bit
 'cause you're like listening and then also hearing a voice.
 But I think at least having the option of something
 that would be able to talk to you would be nice.
 And then as for what you said about like
 having it be able to highlight something,
 I think that could also definitely be super useful
 just 'cause it would be really,
 it would save a lot of time.
 Sort of like, I think one of the best examples
 I can think of right now is like the mastering assistant
 in Ozone.
 Really like it can detect frequencies very quickly
 and give you like a template to work with super quickly.
 And I find that that saves me so much time
 'cause I can still make all the changes
 to make it sound how I want,
 but it gives me a baseline to work with that isn't nothing.
 So yeah, if it can highlight,
 if it could even like detect
 and maybe give you a rough EQ of something.

Speaker SPEAKER_02: 3993.1s - 3993.5s


Speaker SPEAKER_01: 4003.4s - 4006.7s
But yeah, I think there's a lot that it, there's a lot that it could do.

Speaker SPEAKER_00: 4007.9s - 4016.4s
- Yeah, of course.
 I mean, I think the options are limitless,
 but the research funding is limited.
 So it's like, all right, what?

Speaker SPEAKER_06: 4016.7s - 4030.5s
I feel like the best possible, like the dream is like the guy who does the voiceover training
 in the Spider-Man video games.
 That would be like your dream co-mixing partner and he's telling you, do this, do that.

Speaker SPEAKER_02: 4023.9s - 4024.4s


Speaker SPEAKER_03: 4024.4s - 4024.5s


Speaker SPEAKER_02: 4029.8s - 4029.8s


Speaker SPEAKER_00: 4029.8s - 4030.5s


Speaker SPEAKER_00: 4032.1s - 4078.8s
I guess in terms of like what features,
 what's the number one feature you think it could improve
 in mixing?
 So TJ, you were saying like, okay, a baseline
 so that I can really work off it.
 But is there any other, you know, one feature
 that would be really, really helpful?
 Would it be like labeling markers, for example,
 or something as like you were stemming things together,
 right, should automatically do that for you and say like,
 hey, based on these instrument profiles,
 I've already stemmed these together for you.
 Are those helpful or do you want more nuanced mixing
 like a notch filter versus a bandpass or like a compression?
 Do you want a sidechain or not, et cetera?
 Like, are those helpful or what is the like one thing

Speaker SPEAKER_06: 4080.5s - 4083.3s
- Yeah, I feel like the grouping, automatic grouping.

Speaker SPEAKER_03: 4080.5s - 4080.9s


Speaker SPEAKER_06: 4084.5s - 4085.2s


Speaker SPEAKER_01: 4084.7s - 4114.9s
Yeah, that could be super, super helpful. I think it can also depend on the mixer. I'm someone who,
 depending on what I'm working on, there are times when I just kind of want to focus on the creative
 elements and not have to worry about the technical grouping stuff as much. Then there are times where
 I want much more control over what I'm doing technically. So I think it'd be nice if there
 was like, you could sort of be working on a session and you could sort of tell your...

Speaker SPEAKER_01: 4115.6s - 4147.1s
AI partner, how much help you're wanting with this session
 for workflow, if you want it to really help
 like kind of be doing background balancing
 and stuff at all times
 so that you can really just focus on your creative vision.
 Maybe if you're trying to put together a demo really quick,
 that could be super nice.
 But then if you wanna go in later
 and really fine tune things, you can.
 But as far as like a feature goes
 that I think would be really helpful,
 I would, um...

Speaker SPEAKER_01: 4148.1s - 4158.1s
I think it'd be really nice if you could describe what you're wanting to do.
 It could give you an industry standard, but it could also, um, maybe connect you to like.

Speaker SPEAKER_01: 4159.4s - 4160.0s


Speaker SPEAKER_01: 4161.4s - 4173.9s
like human resources who are doing like putting into practice exactly what it is that you're trying to do. So if you could say like, Hey, I want to do like a like you and I were talking about having um

Speaker SPEAKER_01: 4175.2s - 4196.1s
like a really reverb distorted guitar.
 Let's say we had no idea how to word that
 or how to do that.
 We could say like, how could we do this?
 Could you give us some examples of this being done?
 Maybe it could take us to a video,
 a moment in a YouTube video where this is being done,
 put together some examples of like songs
 that it's been done in.
 - Exactly, that would be great.

Speaker SPEAKER_06: 4194.9s - 4197.3s
- Exactly, that would be great reference tracks.

Speaker SPEAKER_01: 4197.3s - 4202.1s
real-world application outside of what we're working on if it can pull those together.

Speaker SPEAKER_00: 4204.1s - 4205.6s
It's a really good idea.

Speaker SPEAKER_00: 4206.7s - 4209.8s
No idea how to implement that at all, but that would be rad.

Speaker SPEAKER_01: 4210.3s - 4211.5s
Are you building this, or?

Speaker SPEAKER_00: 4212.0s - 4285.6s
- Yeah, so this is part of it necessarily.
 I've been working on automatic audio effect,
 one classification.
 So based on a track, what should it actually provide?
 So should it have an EQ?
 Should you pan it left, right?
 Automatic gain staging,
 and then also like chorus, flanger, limiter,
 compression, et cetera.
 And then based on that values parameters,
 so which parameters to change and then also which value.
 So I'm doing mine based on a lot of these open source models
 and that kind of goes to my last question,
 which was there's a lot of things about like AI,
 stealing from artists work,
 which is obviously very ridiculous in terms of like,
 we're all trying to create creative products
 and that limits creativity to some degree.
 But if the co-creative agent produces recommendations
 that are heavily influenced by specific artists
 or work in the training data,
 such as you're saying like a reference track,
 how do you believe credit and attribution should be handled?
 So should there be a system in place to acknowledge
 and compensate original creators,
 or is it enough to say, okay,
 this was taken most likely from this reference,
 or is there another way you believe
 they should be compensated and attributed for this?

Speaker SPEAKER_06: 4287.3s - 4322.4s
Yeah, when I think about it, I feel like there should be maybe like kind of a set number of tracks and then you could always ask the artist, like, would you consent to being included in this so that when they say yes, and it provides you like this is this track by Billie Eilish and Phineas, ideally they know that if that's going on, sort of like how Apple logic gives you the templates of like Lil Nas X and things like that for the new version.
 Like it kind of in collaboration with if that's possible, but I know that'd be very hard.

Speaker SPEAKER_02: 4320.8s - 4321.1s


Speaker SPEAKER_01: 4323.8s - 4364.5s
I would say it really, it depends on what, if the AI is doing, or if the AI is suggesting, for example, like, I feel like Flume, the producer, I mean, he's done so much revolutionary stuff with granular synthesis.
 And if I ask an AI, can you help me make something that sounds like a, like a flume synth?
 Then at that point, I feel like as an artist, I'm, I'm, I'm trying to make something that sounds like an artist that I like, versus describing something to an AI.
 and.

Speaker SPEAKER_01: 4365.3s - 4371.6s
the AI like analyzing tracks from Flume and then like.

Speaker SPEAKER_01: 4372.7s - 4381.3s
doing it for me copying and making its own adjustments.
 I think the reason is because it's hard to like.

Speaker SPEAKER_01: 4382.2s - 4382.9s


Speaker SPEAKER_01: 4384.3s - 4386.2s
It's hard to say to, um.

Speaker SPEAKER_01: 4388.4s - 4395.7s
like a, you can say to an artist, like you intentionally copied my stuff, but can you say to an AI like.

Speaker SPEAKER_01: 4396.5s - 4397.0s


Speaker SPEAKER_01: 4398.2s - 4405.3s
You can you, can you, can that responsive, can an AI be held responsible for, for that?
 So I don't know.

Speaker SPEAKER_01: 4406.7s - 4420.1s
It's hard because like a human could probably and it would take longer but could do the exact same thing could just listen and try to recreate sounds. I mean, I do that all the time. If I hear a production I like I'll try to recreate it.
 [BLANK_AUDIO]

Speaker SPEAKER_01: 4421.0s - 4424.8s
But I definitely think the question of whether an AI like.

Speaker SPEAKER_01: 4425.8s - 4428.2s
can do it as almost.

Speaker SPEAKER_01: 4428.9s - 4439.1s
Irrelevant because we know they can do it just like a human can that's sort of the goal of the question
 I think that you asked is
 whether or not

Speaker SPEAKER_01: 4439.7s - 4443.6s
artists should be like compensated or acknowledged and I would say.

Speaker SPEAKER_01: 4444.7s - 4467.5s
Whatever existing laws we have in the music industry to deal with that, to deal with copyright or trademark or a signature sound being stolen, we should adapt those to incorporate the use of AI companions, rather than create a whole new bunch of laws to try to
 try to, um.

Speaker SPEAKER_01: 4468.9s - 4470.6s
to try to factor them in.

Speaker SPEAKER_01: 4472.7s - 4473.5s


Speaker SPEAKER_06: 4473.0s - 4488.7s
It's hard because I feel like to AI is such like it's a blend of so many artists.
 But when you're going to it and asking for like
 give me like a Keycharnada beat like exactly like one specific artist.

Speaker SPEAKER_06: 4489.4s - 4515.9s
I it's hard to say where I feel like you should have to change
 it enough to sort of make it your own but to just use the
 preset or something that has been analyzed to sound like
 them. It feels like this should have a little bit of a credit to
 them in the end, like use with this AI inspired by this artist
 and that might be like in the full production notes, but they
 might not necessarily get paid for it.

Speaker SPEAKER_00: 4517.4s - 4520.2s
Yeah.
 I mean, there's, Oh, sorry.

Speaker SPEAKER_06: 4517.9s - 4518.0s


Speaker SPEAKER_01: 4518.0s - 4518.4s


Speaker SPEAKER_01: 4520.7s - 4544.6s
I would say at least, I mean, as far as I know, they've yet to
 develop a will of their own.
 I think it's if two AIs get together and start copying, like copying Billy
 Eilish and Phineas or copying Jack Antonoff, then I'm going to have a problem.
 But like a human is using an AI to help get the Jack Antonoff sound or to get
 the Billy Eilish and Phineas sound, like.

Speaker SPEAKER_01: 4546.3s - 4563.5s
I mean, yeah, you should probably be doing your own things to it. So it's maintain some level of originality some something you but I think I don't think that ethical implications with using an AI to help you to achieve that come in as much unless
 Um.

Speaker SPEAKER_01: 4564.7s - 4568.9s
Unless the AI is doing that based on a will of its own.

Speaker SPEAKER_06: 4570.5s - 4604.4s
- It's a hard discussion 'cause we're using this,
 like we're talking about it as artists
 who want to make our own choices,
 but I specifically think of it in the context too
 of like people who make music for reality shows,
 people who are making music songs for commercials.
 If I like can go to an AI and say,
 make like a slightly tweaked version in notes of this track,
 that's where I feel like more credit needs to be given.
 Whereas we're talking about using it as a tool
 and like in the absolute worst case,
 it might be used to just kind of like keep regurgitating the same songs over and over.

Speaker SPEAKER_01: 4570.6s - 4570.8s


Speaker SPEAKER_03: 4570.8s - 4571.5s


Speaker SPEAKER_01: 4605.2s - 4634.4s
Yeah. And I, I mean, Michael, you can correct me if I'm wrong,
 but I believe like as even with all the like vast amounts of data that
 AIs take in and they can make connections between probably even better than
 humans, they can pinpoint where they are getting things from.
 So if art, if it is,
 if they're extrapolating from things and they are,
 and they output something based on the connections they have probably even
 better than a human, they can sort of, um,

Speaker SPEAKER_01: 4635.3s - 4648.2s
they can they can determine where they got something from so you could get a little
 thing in your bank account as billy eilish that says hey this ai model that you've given
 access to your catalog to has used it to like you know took generating whatever

Speaker SPEAKER_06: 4648.5s - 4650.1s
- Exactly, exactly.

Speaker SPEAKER_01: 4650.0s - 4659.0s
So people can end up having really cool passive income streams because they've allowed their stuff to be accessed by AIs.

Speaker SPEAKER_01: 4660.1s - 4698.4s
I mean, maybe at least as an artist, what I'm more afraid of is, because it's very flattering
 when people want to mimic you.
 And essentially somebody telling an AI to do that is still at its heart, a person wanting
 to do that.
 So if that AI, the same way a person would be able to, is able to give you credit, acknowledge
 you, compensation when it's due, then I think that just like, it really, it honestly enhances
 the ability for humans to be able to bounce off each other and to create, be fueled off
 each other's creativity rather than feeling like it's some sort of war where you have
 to protect everything.

Speaker SPEAKER_01: 4700.1s - 4709.2s
So AI may, what I'm saying is it may offer up the opportunity to do that even
 more accurately and more ethically and figure out where things are being sourced from.

Speaker SPEAKER_00: 4710.6s - 4772.2s
- Yeah, 'cause right now the discourse is around
 Suno and Aute Udeo, the two like primary ones
 where it's text to music gen
 and like where they got all the music labels
 and things of that nature.
 It's still obviously proprietary,
 but we as a community have kind of figured out
 where they got it from
 and how they're training on all this data.
 So it's like, okay, now what do we do
 and how our royalty is going to be paid, et cetera.
 'Cause yeah, I think you're right, TJ,
 like that's where it's going essentially.
 It's like royalty-based kind of,
 and you have to bake it into the model
 of back propagating to where you found the actual result,
 but you can do that.
 You can build models that say, okay,
 I'm like 80% confident that I took it from this reference,
 which is right, then you could divvy up the actual amount
 that was used to generate that and like whatever.
 You pay back the royalties on that,
 which I don't know what Spotify does for plays,
 but it's something similar where you get like a royalty
 on a play for blah, blah, blah.

Speaker SPEAKER_00: 4772.9s - 4825.3s
So, but yes, so at any rate, I'm training only
 on non-copyrighted data right now.
 So everything is open source
 and that's where this mix came from.
 It was from the Mixing Secrets from Mike Senior is his name.
 He's a UK Cambridge mixing artist
 and he's been doing this for like 35 years.
 At any rate, he has a whole collection
 of just totally non-copyright music
 that people have recorded together
 and they use it for mixing projects basically.
 So you get the full stems
 and then you can mix it down however you want.
 And so this is what a lot of people use
 in like different classrooms or whatever.
 So it's just basically a workbook
 but this is what I'm doing.
 And then I had annotated DAW sessions.
 I hand annotated all the audio effects
 and all the parameters, et cetera.
 So we'll see how it goes, but yeah,
 that's about my project, so.

Speaker SPEAKER_03: 4825.8s - 4827.6s
- This is so cool.

Speaker SPEAKER_00: 4826.0s - 4826.0s


Speaker SPEAKER_01: 4826.0s - 4826.2s


Speaker SPEAKER_01: 4827.3s - 4834.5s
I would love to be kept up on your progress or if you end up sharing something at some point i'd love to see it

Speaker SPEAKER_00: 4827.6s - 4827.8s


Speaker SPEAKER_00: 4833.7s - 4834.5s


Speaker SPEAKER_00: 4836.0s - 4843.5s
- Well, thank you.
 I've been working with music producers for a while.
 Jackie knows this.
 I'm sorry for always asking you for help, but thank you.

Speaker SPEAKER_06: 4842.5s - 4855.2s
Oh my god, I'm so excited. I feel like you're just so much more advanced than me.
 Even in high school, you were pre-programming your little controller to do amazing things,
 and I was always very impressed. I knew you were going to do great things.

Speaker SPEAKER_00: 4851.8s - 4852.8s


Speaker SPEAKER_00: 4855.6s - 4862.5s
some things eventually. But for the payment, are the emails okay that I've been using to contact?

Speaker SPEAKER_00: 4863.5s - 4965.3s
- So, okay.
 The process for that is I immediately send your emails
 over to Utah and then they send you the Amazon gift cards.
 If you don't get it within like a week,
 just ping me and let me know.
 Stacy is sometimes out of office.
 So it normally gets passed.
 Summer is kind of difficult.
 Just admin for schools.
 Sometimes people are there, sometimes they're not.
 But I will get it to you ASAP
 and it will be paid in the Amazon gift card.
 So if you have any questions about that,
 feel free to contact me always.
 Thank you again for your time.
 And yeah, if you have any other questions here,
 you can ask now or like just ping me whenever.
 And then I'll keep you up to date on all the research.
 We're going to try to put this into a paper in AAAI,
 which is, oh goodness.
 It's like the advances of artificial intelligence.
 It's something, it's like the premiere AI conference
 and that one's all the way in, I think, August.
 So we're using a lot of the data
 that we've been collecting for the last year
 and the models we've been training for this.
 But this piece of it is just to understand
 more or less the explainability portion.
 So when giving explanations behind the recommendations,
 how should we give them and in what capacity?
 So like what you were saying, TJ, I'm like,
 maybe I don't want to be bothered right now
 on that kind of stuff.
 Maybe I want to be bothered on like another,
 or you take the lift on this.
 So that's what we're trying to understand.
 So thank you again for everything.
 For the session, that's a good question.
 I could open up the drive
 and you could dump it in there if you want,
 or I don't know how else you would like to send it.

Speaker SPEAKER_01: 4961.6s - 4961.7s


Speaker SPEAKER_01: 4962.6s - 4962.9s


Speaker SPEAKER_01: 4966.3s - 4970.2s
I mean, yeah, I could put like a zip file in the drive.
 That would probably be the easiest.

Speaker SPEAKER_00: 4970.8s - 4972.7s
Cool. Yeah, that would be great if possible.

Speaker SPEAKER_01: 4973.3s - 4989.5s
- Yeah, third-party plugins, we used a few.
 So I can include like a bounced version of it too,
 just so if you open the session
 and there's like a bunch missing,
 like the decapitator, fresh air,
 you can at least, you have the mix somewhere.

Speaker SPEAKER_00: 4976.5s - 4977.1s


Speaker SPEAKER_00: 4988.8s - 4998.8s
- Yeah, I have, I don't have fresh air,
 but I have Decapitator and Valhalla.
 So I should be okay with those two.
 Yeah, I'm just missing fresh air.
 So I think I should be good, but thank you.

Speaker SPEAKER_03: 4993.9s - 4996.6s
I should be okay with those two.

Speaker SPEAKER_01: 4999.6s - 5021.3s
Yeah. Um, I have one last question actually for Jackie. Thank you again for all your help today.
 This was really fun. Um, I heard that you did podcasting stuff. Um, I am potentially at some
 point in the future for my senior project going to be doing stuff that has to do with podcasting.
 Would it potentially be okay to just reach out to you as a resource?

Speaker SPEAKER_06: 5021.0s - 5026.5s
100%. I would love to work with you. Thank you so much. Of course, yes.

Speaker SPEAKER_01: 5024.3s - 5025.0s


Speaker SPEAKER_01: 5026.4s - 5030.0s
I'm constantly looking for people who know more about that world of audio than I do.

Speaker SPEAKER_06: 5030.0s - 5069.8s
- Well, if you want to listen to the show and be like,
 wow, this is awful, I shouldn't reach out to her for help.
 It's called the Art Law Podcast.
 And I'm also working on another show called
 Woman of Culture Podcast with very little editing.
 But yeah, my main show is the Art Law Podcast
 and that's like my baby.
 The hard part is they've been using Zoom interviews
 a lot since COVID, but the cool thing is we get
 to interview people around the world.
 Exactly, yes.
 So it's kind of a step up from only being able
 to interview people in person, but terrible sound
 because my bosses need video, they're old.
 They just need the video.
 (laughing)

Speaker SPEAKER_03: 5033.9s - 5036.9s
I shouldn't reach out to her for help.
 It's called the art.

Speaker SPEAKER_03: 5041.6s - 5042.9s
with very little-- - The heart.

Speaker SPEAKER_01: 5070.0s - 5084.6s
Yeah, I'll listen to this. This looks really cool. Like the
 descriptions of what the episodes are about. I'd love to
 be able to reach out to you at some point. And yeah, thank you
 again. This was a really fun experience meeting you both.
 - So cool. - Yeah.

Speaker SPEAKER_00: 5083.0s - 5083.5s


Speaker SPEAKER_00: 5084.1s - 5098.4s
- Yeah, no, thank you so much.
 And I can exchange.
 Jackie, do you want me to provide email to TJ
 and like your contact info?
 Okay, I'll do that in like the follow-up email.
 So TJ, you'll have all the information that you need
 to contact Jackie whenever.

Speaker SPEAKER_03: 5090.5s - 5091.6s
and like your contact info?

Speaker SPEAKER_02: 5091.3s - 5091.4s


Speaker SPEAKER_03: 5092.3s - 5092.6s


Speaker SPEAKER_01: 5099.1s - 5102.4s
and I'll get the session in that same drive folder for you.

Speaker SPEAKER_00: 5102.5s - 5104.6s
Awesome. Thank you so much. Appreciate it.

Speaker SPEAKER_00: 5105.6s - 5111.1s
All right, thank you. Have a good Friday. Have a good weekend. But I'll catch you all later. Have a good one.

Speaker SPEAKER_06: 5108.5s - 5108.6s


Speaker SPEAKER_06: 5111.5s - 5112.0s


Speaker SPEAKER_00: 5111.8s - 5111.8s


